#!/usr/bin/env python3
"""
æ±‡æ€»è¯„ä¼°ç»“æœè„šæœ¬

åŠŸèƒ½ï¼š
1. æŠŠ eval/results/ é‡Œé¢å•ä¸ª conv è·‘çš„ç»“æœæ±‡æ€»æˆæ€»ç»“æœ
2. æ¯ä¸ª conv å¦‚æœæœ‰å¤šè½®çš„è¯ç›´æ¥é€‰æ‹©æœ€æ–°çš„ï¼ˆä¾‹å¦‚ conv0, conv0-1, conv0-2 é€‰æ‹© conv0-2ï¼‰
3. ç”ŸæˆåŒ…å«æ€»åˆ†æ•°ã€å…·ä½“è·¯å¾„ã€é”™é¢˜åˆ—è¡¨ã€åˆ†ç±»ç»Ÿè®¡çš„å…¨é¢æŠ¥å‘Š
"""

import argparse
import json
import re
import sys
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Optional


def find_latest_conv_dirs(results_dir: Path) -> dict[int, Path]:
    """
    æ‰¾åˆ°æ¯ä¸ª conv çš„æœ€æ–°ç›®å½•ã€‚

    ä¾‹å¦‚ï¼šconv0, conv0-1, conv0-2 -> é€‰æ‹© conv0-2

    Returns:
        dict: {conv_id: latest_dir_path}
    """
    conv_pattern = re.compile(r'^locomo-conv(\d+)(?:-(\d+))?$')

    # æ”¶é›†æ‰€æœ‰ conv ç›®å½•
    conv_dirs: dict[int, list[tuple[int, Path]]] = defaultdict(list)

    for d in results_dir.iterdir():
        if not d.is_dir():
            continue

        match = conv_pattern.match(d.name)
        if match:
            conv_id = int(match.group(1))
            version = int(match.group(2)) if match.group(2) else 0
            conv_dirs[conv_id].append((version, d))

    # é€‰æ‹©æ¯ä¸ª conv çš„æœ€æ–°ç‰ˆæœ¬
    latest_dirs = {}
    for conv_id, versions in conv_dirs.items():
        # æŒ‰ç‰ˆæœ¬å·æ’åºï¼Œé€‰æ‹©æœ€å¤§çš„
        versions.sort(key=lambda x: x[0], reverse=True)
        latest_dirs[conv_id] = versions[0][1]

    return latest_dirs


def load_eval_results(eval_file: Path) -> Optional[dict]:
    """åŠ è½½è¯„ä¼°ç»“æœ JSON æ–‡ä»¶"""
    if not eval_file.exists():
        return None

    try:
        with open(eval_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        print(f"âš ï¸  æ— æ³•åŠ è½½ {eval_file}: {e}")
        return None


def aggregate_results(latest_dirs: dict[int, Path]) -> dict:
    """
    æ±‡æ€»æ‰€æœ‰ conv çš„ç»“æœ

    Returns:
        dict: åŒ…å«æ±‡æ€»ç»Ÿè®¡å’Œè¯¦ç»†ä¿¡æ¯çš„å­—å…¸
    """
    total_questions = 0
    total_correct = 0

    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    category_stats = defaultdict(lambda: {'total': 0, 'correct': 0})

    # é”™é¢˜åˆ—è¡¨
    wrong_answers = []

    # å„ conv çš„è¯¦ç»†ä¿¡æ¯
    conv_details = {}

    # æŒ‰ conv_id æ’åºå¤„ç†
    for conv_id in sorted(latest_dirs.keys()):
        dir_path = latest_dirs[conv_id]
        eval_file = dir_path / 'eval_results.json'

        results = load_eval_results(eval_file)
        if results is None:
            conv_details[conv_id] = {
                'path': str(dir_path),
                'status': 'missing',
                'total': 0,
                'correct': 0,
                'accuracy': 0.0
            }
            continue

        conv_total = results.get('total_questions', 0)
        conv_correct = results.get('correct', 0)
        conv_accuracy = results.get('accuracy', 0.0)

        total_questions += conv_total
        total_correct += conv_correct

        conv_details[conv_id] = {
            'path': str(dir_path),
            'status': 'ok',
            'total': conv_total,
            'correct': conv_correct,
            'accuracy': conv_accuracy
        }

        # å¤„ç†è¯¦ç»†ç»“æœ
        detailed_results = results.get('detailed_results', {})
        for user_id, questions in detailed_results.items():
            for q in questions:
                category = str(q.get('category', 'unknown'))
                category_stats[category]['total'] += 1

                # åˆ¤æ–­æ˜¯å¦æ­£ç¡®ï¼ˆå¤šæ•°åˆ¤å†³ï¼‰
                judgments = q.get('llm_judgments', {})
                true_count = sum(1 for v in judgments.values() if v)
                is_correct = true_count >= 2

                if is_correct:
                    category_stats[category]['correct'] += 1
                else:
                    wrong_answers.append({
                        'conv_id': conv_id,
                        'question_id': q.get('question_id', 'unknown'),
                        'question': q.get('question', ''),
                        'golden_answer': q.get('golden_answer', ''),
                        'generated_answer': q.get('generated_answer', ''),
                        'category': category,
                        'judgments': judgments
                    })

    # è®¡ç®—æ€»å‡†ç¡®ç‡
    overall_accuracy = total_correct / total_questions if total_questions > 0 else 0.0

    return {
        'total_questions': total_questions,
        'total_correct': total_correct,
        'overall_accuracy': overall_accuracy,
        'conv_details': conv_details,
        'category_stats': dict(category_stats),
        'wrong_answers': wrong_answers
    }


def get_category_name(category: str) -> str:
    """
    è·å–ç±»åˆ«çš„å¯è¯»åç§°

    LoCoMo æ•°æ®é›†ç±»åˆ«å®šä¹‰ï¼ˆæ ¹æ® evidence æ•°é‡å’Œé—®é¢˜å†…å®¹åˆ†æï¼‰:
    - Category 1: Multi-hop (å¤šè·³) - å¹³å‡ 3+ ä¸ª evidenceï¼Œéœ€è¦ç»¼åˆå¤šå¤„ä¿¡æ¯
    - Category 2: Temporal (æ—¶åº) - 91% æ˜¯ When é—®é¢˜ï¼Œæ—¶é—´ç›¸å…³æ¨ç†
    - Category 3: Commonsense (å¸¸è¯†) - éœ€è¦å¸¸è¯†æˆ–ä¸–ç•ŒçŸ¥è¯†æ¨ç†
    - Category 4: Single-hop (å•è·³) - 95% å•è¯æ®ï¼Œç›´æ¥äº‹å®æŸ¥è¯¢
    - Category 5: Adversarial (å¯¹æŠ—æ€§) - ä¸å¯å›ç­”çš„é—®é¢˜
    """
    category_names = {
        '1': 'Multi-hop (å¤šè·³)',
        '2': 'Temporal (æ—¶åº)',
        '3': 'Commonsense (å¸¸è¯†)',
        '4': 'Single-hop (å•è·³)',
        '5': 'Adversarial (å¯¹æŠ—æ€§)',
        'unknown': 'Unknown (æœªçŸ¥)'
    }
    return category_names.get(category, f'Category {category}')


def generate_summary(aggregated: dict) -> str:
    """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Šï¼ˆç”¨äºå±å¹•æ‰“å°ï¼‰"""
    lines = []

    # æ ‡é¢˜
    lines.append("=" * 70)
    lines.append("ğŸ“Š LoCoMo è¯„ä¼°æ±‡æ€»æŠ¥å‘Š")
    lines.append("=" * 70)
    lines.append("")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")

    # æ€»ä½“ç»Ÿè®¡
    lines.append("-" * 70)
    lines.append("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡")
    lines.append("-" * 70)
    lines.append(f"æ€»é—®é¢˜æ•°: {aggregated['total_questions']}")
    lines.append(f"æ­£ç¡®æ•°:   {aggregated['total_correct']}")
    lines.append(f"å‡†ç¡®ç‡:   {aggregated['overall_accuracy']:.2%}")
    lines.append(f"é”™é¢˜æ•°:   {len(aggregated['wrong_answers'])}")
    lines.append("")

    # å„ conv è¯¦æƒ…
    lines.append("-" * 70)
    lines.append("ğŸ“ å„å¯¹è¯è¯¦æƒ…")
    lines.append("-" * 70)
    lines.append("")
    lines.append(f"{'Conv':<8} {'çŠ¶æ€':<10} {'æ­£ç¡®/æ€»æ•°':<12} {'å‡†ç¡®ç‡':<10} è·¯å¾„")
    lines.append("-" * 70)

    for conv_id in sorted(aggregated['conv_details'].keys()):
        detail = aggregated['conv_details'][conv_id]
        status = 'âœ…' if detail['status'] == 'ok' else 'âŒ'
        if detail['status'] == 'ok':
            score = f"{detail['correct']}/{detail['total']}"
            accuracy = f"{detail['accuracy']:.2%}"
        else:
            score = "-"
            accuracy = "-"

        # æå–ç›¸å¯¹è·¯å¾„
        path = detail['path']
        if 'eval/results/' in path:
            path = path.split('eval/results/')[-1]
        elif 'eval\\results\\' in path:
            path = path.split('eval\\results\\')[-1]

        lines.append(f"conv{conv_id:<4} {status:<10} {score:<12} {accuracy:<10} {path}")

    lines.append("")

    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    lines.append("-" * 70)
    lines.append("ğŸ“Š æŒ‰ç±»åˆ«ç»Ÿè®¡")
    lines.append("-" * 70)
    lines.append("")
    lines.append(f"{'ç±»åˆ«':<30} {'æ­£ç¡®/æ€»æ•°':<15} {'å‡†ç¡®ç‡':<10}")
    lines.append("-" * 70)

    for category in sorted(aggregated['category_stats'].keys()):
        stats = aggregated['category_stats'][category]
        cat_name = get_category_name(category)
        score = f"{stats['correct']}/{stats['total']}"
        accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0.0
        lines.append(f"{cat_name:<30} {score:<15} {accuracy:.2%}")

    lines.append("")
    lines.append("=" * 70)

    return '\n'.join(lines)


def generate_full_report(aggregated: dict) -> str:
    """ç”Ÿæˆå®Œæ•´æŠ¥å‘Šï¼ˆåŒ…å«æŒ‰ç±»åˆ«å½’ç±»çš„é”™é¢˜åˆ—è¡¨ï¼Œç”¨äºä¿å­˜åˆ°æ–‡ä»¶ï¼‰"""
    lines = [generate_summary(aggregated)]

    # æŒ‰ç±»åˆ«åˆ†ç»„é”™é¢˜
    from collections import defaultdict
    wrong_by_category = defaultdict(list)
    for wrong in aggregated['wrong_answers']:
        wrong_by_category[wrong['category']].append(wrong)

    # é”™é¢˜åˆ—è¡¨ï¼ˆæŒ‰ç±»åˆ«å½’ç±»ï¼‰
    lines.append("")
    lines.append("-" * 70)
    lines.append(f"âŒ é”™é¢˜åˆ—è¡¨ (å…± {len(aggregated['wrong_answers'])} é¢˜)")
    lines.append("-" * 70)

    total_idx = 0
    for category in sorted(wrong_by_category.keys()):
        wrongs = wrong_by_category[category]
        cat_name = get_category_name(category)

        lines.append("")
        lines.append(f"### {cat_name} ({len(wrongs)} é¢˜)")
        lines.append("")

        for wrong in wrongs:
            total_idx += 1
            lines.append(f"[{total_idx}] {wrong['question_id']} (conv{wrong['conv_id']})")
            lines.append(f"    é—®é¢˜: {wrong['question']}")
            lines.append(f"    æ ‡å‡†ç­”æ¡ˆ: {wrong['golden_answer']}")
            generated = wrong.get('generated_answer', '')
            if len(generated) > 200:
                lines.append(f"    ç”Ÿæˆç­”æ¡ˆ: {generated[:200]}...")
            else:
                lines.append(f"    ç”Ÿæˆç­”æ¡ˆ: {generated}")
            lines.append("")

    lines.append("=" * 70)
    lines.append("æŠ¥å‘Šç»“æŸ")
    lines.append("=" * 70)

    return '\n'.join(lines)


def save_results(aggregated: dict, report: str, output_dir: Path):
    """ä¿å­˜ç»“æœåˆ°è¾“å‡ºç›®å½•"""
    output_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜ JSON ç»“æœ
    json_file = output_dir / 'aggregated_results.json'
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(aggregated, f, ensure_ascii=False, indent=2)
    print(f"âœ… JSON ç»“æœå·²ä¿å­˜åˆ°: {json_file}")

    # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
    report_file = output_dir / 'aggregated_report.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"âœ… æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


def find_output_dir(base_name: str, results_dir: Path) -> Path:
    """
    æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„è¾“å‡ºç›®å½•ã€‚

    ç¬¬ä¸€æ¬¡è¿è¡Œ: base_name (e.g., aggregated)
    ç¬¬äºŒæ¬¡è¿è¡Œ: base_name-1 (e.g., aggregated-1)
    ç¬¬ä¸‰æ¬¡è¿è¡Œ: base_name-2 (e.g., aggregated-2)
    """
    base_dir = results_dir / base_name

    if not base_dir.exists():
        return base_dir

    # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„ç¼–å·
    counter = 1
    while (results_dir / f"{base_name}-{counter}").exists():
        counter += 1

    return results_dir / f"{base_name}-{counter}"


def main():
    parser = argparse.ArgumentParser(
        description="æ±‡æ€» LoCoMo è¯„ä¼°ç»“æœ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                    æ±‡æ€»æ‰€æœ‰ conv ç»“æœï¼Œè¾“å‡ºåˆ° eval/results/aggregated/
  %(prog)s --output custom    è¾“å‡ºåˆ° eval/results/custom/ ç›®å½•

æ³¨æ„: æ¯æ¬¡è¿è¡Œä¼šè‡ªåŠ¨åˆ›å»ºæ–°ç›®å½• (aggregated, aggregated-1, aggregated-2, ...)
        """
    )

    parser.add_argument(
        '-o', '--output',
        type=str,
        default='aggregated',
        help='è¾“å‡ºç›®å½•åŸºç¡€åç§° (é»˜è®¤: aggregated)'
    )

    args = parser.parse_args()

    # è·¯å¾„è®¾ç½®
    script_dir = Path(__file__).parent
    results_dir = script_dir / 'results'
    output_dir = find_output_dir(args.output, results_dir)  # è‡ªåŠ¨ç‰ˆæœ¬åŒ–

    if not results_dir.exists():
        print(f"âŒ ç»“æœç›®å½•ä¸å­˜åœ¨: {results_dir}")
        sys.exit(1)

    print("ğŸ” æ‰«æè¯„ä¼°ç»“æœç›®å½•...")
    print(f"   æºç›®å½•: {results_dir}")
    print("")

    # æ‰¾åˆ°æœ€æ–°çš„ conv ç›®å½•
    latest_dirs = find_latest_conv_dirs(results_dir)

    if not latest_dirs:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• conv è¯„ä¼°ç»“æœ")
        sys.exit(1)

    print(f"ğŸ“ æ‰¾åˆ° {len(latest_dirs)} ä¸ªå¯¹è¯çš„è¯„ä¼°ç»“æœ:")
    for conv_id in sorted(latest_dirs.keys()):
        print(f"   conv{conv_id}: {latest_dirs[conv_id].name}")
    print("")

    # æ±‡æ€»ç»“æœ
    print("ğŸ“Š æ­£åœ¨æ±‡æ€»ç»“æœ...")
    aggregated = aggregate_results(latest_dirs)

    # ç”ŸæˆæŠ¥å‘Š
    summary = generate_summary(aggregated)
    full_report = generate_full_report(aggregated)

    # ä¿å­˜ç»“æœï¼ˆå®Œæ•´æŠ¥å‘Šå«é”™é¢˜åˆ—è¡¨ï¼‰
    print("")
    save_results(aggregated, full_report, output_dir)

    # æ‰“å°æ‘˜è¦åˆ°å±å¹•ï¼ˆä¸å«é”™é¢˜è¯¦æƒ…ï¼‰
    print("")
    print(summary)

    return 0


if __name__ == "__main__":
    sys.exit(main())
