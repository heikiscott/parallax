# =====================================================
# Memory System Configuration Template
# 记忆系统配置模板
# =====================================================
#
# SECURITY NOTICE / 安全提示:
# - Copy this file to .env and fill in your actual API keys
# - Never commit .env file to version control
# - Keep your API keys secure and private
# - 将此文件复制为.env并填入您的实际API密钥
# - 永远不要将.env文件提交到版本控制
# - 保护好您的API密钥安全
#
# SETUP INSTRUCTIONS / 设置说明:
# 1. cp env.template .env
# 2. Edit .env with your actual values
# 3. The system will automatically load these values
# =====================================================


# ===================
# LLM Configuration / LLM配置
# ===================

LLM_PROVIDER=openai
# evaluation 请用 openai/gpt-4.1-mini 以保证结果可复现性，demo 可使用 x-ai/grok-4-fast 平衡速度/成本/效果
LLM_MODEL=x-ai/grok-4-fast
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_API_KEY=sk-or-v1-xxxx
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=32768
# openrouter/其他的供应商设置，默认为 default，用 openrouter 的 qwen3 时建议设置为 cerebras
# LLM_OPENROUTER_PROVIDER=cerebras

# OpenAI Provider Retry & Concurrency Configuration / OpenAI Provider重试与并发配置
# 简单且鲁棒的自适应退避策略：根据上次请求耗时动态调整等待时间
OPENAI_TIMEOUT=30                      # API超时(秒)，默认30秒
OPENAI_SDK_MAX_RETRIES=0               # SDK内部重试次数，默认0(完全由应用层控制)
OPENAI_MAX_RETRIES=5                   # 应用层最大重试次数，默认5次
OPENAI_BACKOFF_FACTOR=0.5              # 退避系数，等待时间 = 上次耗时 × 此系数
OPENAI_MIN_BACKOFF=5                   # 最小退避时间(秒)，默认5秒
OPENAI_MAX_BACKOFF=60                  # 最大退避时间(秒)，默认60秒
OPENAI_SLOW_THRESHOLD=15               # 慢请求阈值(秒)，超过此值会警告服务繁忙
OPENAI_MAX_CONCURRENT_REQUESTS=20      # 最大并发数，默认50，防止雪崩

# ===================
# DeepInfra Integration / DeepInfra集成
# ===================

# DeepInfra Embedding Service / DeepInfra嵌入服务配置
# 支持使用本地部署的模型或DeepInfra API
DEEPINFRA_API_KEY=xxxxx
DEEPINFRA_BASE_URL=https://api.deepinfra.com/v1/openai
DEEPINFRA_EMBEDDING_MODEL=Qwen/Qwen3-Embedding-4B
DEEPINFRA_TIMEOUT=30
DEEPINFRA_MAX_RETRIES=3
DEEPINFRA_BATCH_SIZE=10
DEEPINFRA_MAX_CONCURRENT=5
DEEPINFRA_ENCODING_FORMAT=float
DEEPINFRA_DIMENSIONS=1024

# DeepInfra Rerank Service / DeepInfra重排序服务配置
DEEPINFRA_RERANK_BASE_URL=https://api.deepinfra.com/v1/inference
DEEPINFRA_RERANK_MODEL=Qwen/Qwen3-Reranker-4B
DEEPINFRA_RERANK_TIMEOUT=30
DEEPINFRA_RERANK_MAX_RETRIES=3
DEEPINFRA_RERANK_BATCH_SIZE=10
DEEPINFRA_RERANK_MAX_CONCURRENT=5


# ===================
# Redis Configuration / Redis配置
# ===================

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=8
REDIS_SSL=false

# ===================
# MongoDB Configuration / MongoDB配置
# ===================

MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_USERNAME=admin
MONGODB_PASSWORD=memsys123
MONGODB_DATABASE=memsys
MONGODB_URI_PARAMS=socketTimeoutMS=15000&authSource=admin

# ===================
# Elasticsearch Configuration / Elasticsearch配置
# ===================

ES_HOSTS=http://localhost:19200
ES_USERNAME=
ES_PASSWORD=
ES_VERIFY_CERTS=false
SELF_ES_INDEX_NS=memsys

# ===================
# Milvus Configuration / Milvus向量数据库配置
# ===================

MILVUS_HOST=localhost
MILVUS_PORT=19530
SELF_MILVUS_COLLECTION_NS=memsys

# ===================
# API Server Configuration / API服务器配置
# ===================

# V3 API Base URL (用于 chat_with_memory.py 等客户端)
API_BASE_URL=http://localhost:8001

# ===================
# Evaluation Configuration / 评估配置
# ===================

# Concurrency settings for each evaluation stage (避免API限流)
# Recommended for OpenAI free tier: 3-5, paid tier: 10-20

# MemUnit extraction concurrency (LLM-intensive, most strict)
EVAL_EXTRACTION_MAX_CONCURRENT=5

# Index building concurrency (Embedding API, batch processing)
EVAL_INDEXING_MAX_CONCURRENT=5

# Memory retrieval concurrency (includes Agentic retrieval with LLM)
EVAL_RETRIEVAL_MAX_CONCURRENT=5

# Response generation concurrency (LLM answer generation)
EVAL_RESPONSE_MAX_CONCURRENT=5

# LLM-as-a-Judge evaluation concurrency
EVAL_JUDGMENT_MAX_CONCURRENT=5

# ===================
# Environment & Logging / 环境与日志配置
# ===================

LOG_LEVEL=INFO
ENV=dev
PYTHONASYNCIODEBUG=1
MEMORY_LANGUAGE=zh
